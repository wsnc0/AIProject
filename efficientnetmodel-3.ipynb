{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-19T03:45:31.161860Z",
     "iopub.status.busy": "2025-03-19T03:45:31.161537Z",
     "iopub.status.idle": "2025-03-19T03:45:34.752956Z",
     "shell.execute_reply": "2025-03-19T03:45:34.750994Z",
     "shell.execute_reply.started": "2025-03-19T03:45:31.161830Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T05:40:36.926284Z",
     "iopub.status.busy": "2025-03-19T05:40:36.925906Z",
     "iopub.status.idle": "2025-03-19T05:40:36.931551Z",
     "shell.execute_reply": "2025-03-19T05:40:36.930584Z",
     "shell.execute_reply.started": "2025-03-19T05:40:36.926251Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "transformation_for_train = transforms.Compose(\n",
    "    [transforms.Resize((380,380)), \n",
    "     transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "     ]\n",
    ")\n",
    "transformation_for_valntest = transforms.Compose(\n",
    "    [transforms.Resize((380, 380)),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "     ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T05:43:11.706801Z",
     "iopub.status.busy": "2025-03-19T05:43:11.706506Z",
     "iopub.status.idle": "2025-03-19T05:44:30.937713Z",
     "shell.execute_reply": "2025-03-19T05:44:30.937013Z",
     "shell.execute_reply.started": "2025-03-19T05:43:11.706779Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "\n",
    "train_path = \".\\data\"\n",
    "\n",
    "train_dataset= datasets.ImageFolder(root=train_path, transform=transformation_for_train)\n",
    "val_dataset= datasets.ImageFolder(root=val_path, transform=transformation_for_valntest)\n",
    "test_dataset= datasets.ImageFolder(root=test_path, transform=transformation_for_valntest)\n",
    "batchsize = 32\n",
    "\n",
    "train_loader= DataLoader(train_dataset, batch_size=batchsize,shuffle=True)\n",
    "val_loader= DataLoader(val_dataset, batch_size=batchsize,shuffle=True)\n",
    "test_loader= DataLoader(test_dataset, batch_size=batchsize,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T05:45:53.736054Z",
     "iopub.status.busy": "2025-03-19T05:45:53.735744Z",
     "iopub.status.idle": "2025-03-19T05:45:54.283642Z",
     "shell.execute_reply": "2025-03-19T05:45:54.282822Z",
     "shell.execute_reply.started": "2025-03-19T05:45:53.736023Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "def unnormalize(img):\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3,1,1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(3,1,1)\n",
    "    return img * std + mean\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15,5))\n",
    "for i in range(5):\n",
    "    img = unnormalize(images[i])  \n",
    "    img = img.permute(1, 2, 0).numpy()  \n",
    "    img = img.clip(0, 1) \n",
    "    axes[i].imshow(img)\n",
    "    axes[i].axis(\"off\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:02:05.522784Z",
     "iopub.status.busy": "2025-03-19T06:02:05.522500Z",
     "iopub.status.idle": "2025-03-19T06:02:05.727888Z",
     "shell.execute_reply": "2025-03-19T06:02:05.727211Z",
     "shell.execute_reply.started": "2025-03-19T06:02:05.522762Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch.nn as nn \n",
    "efficientnetmodel = models.efficientnet_b4(pretrained=True)\n",
    "no_features = efficientnetmodel.classifier[1].in_features  \n",
    "efficientnetmodel.classifier[1] = nn.Linear(no_features, 1) \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "efficientnetmodel = efficientnetmodel.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:03:18.605465Z",
     "iopub.status.busy": "2025-03-19T06:03:18.605157Z",
     "iopub.status.idle": "2025-03-19T06:03:18.609654Z",
     "shell.execute_reply": "2025-03-19T06:03:18.608674Z",
     "shell.execute_reply.started": "2025-03-19T06:03:18.605442Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def freeze_everything_except_classifier(model):\n",
    "    for params in model.features.parameters():\n",
    "        params.requires_grad=False\n",
    "    print(\"phase 1 - only training classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:03:24.865587Z",
     "iopub.status.busy": "2025-03-19T06:03:24.865261Z",
     "iopub.status.idle": "2025-03-19T06:03:24.870307Z",
     "shell.execute_reply": "2025-03-19T06:03:24.869292Z",
     "shell.execute_reply.started": "2025-03-19T06:03:24.865562Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def unfreeze_last_block(model):\n",
    "    for name,params in model.named_parameters():\n",
    "        #if \"features.6\" in name or \"features.7\" in name or \"classifier\" in name:\n",
    "        if \"features.7\" in name or \"classifier\" in name: \n",
    "            params.requires_grad = True\n",
    "        else:\n",
    "            params.requires_grad = False\n",
    "    print(\"phase 2 - training last 2 blocks and classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:03:37.037380Z",
     "iopub.status.busy": "2025-03-19T06:03:37.037032Z",
     "iopub.status.idle": "2025-03-19T06:03:37.041726Z",
     "shell.execute_reply": "2025-03-19T06:03:37.040878Z",
     "shell.execute_reply.started": "2025-03-19T06:03:37.037346Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def unfreeze_last_two_blocks(model):\n",
    "    for name, params in model.named_parameters():\n",
    "        #if \"features.4\" in name or \"features.5\" in name or \"features.6\" in name or \"features.7\" in name or \"classifier\" in name:\n",
    "        if \"features.6\" in name or \"features.7\" in name or \"classifier\" in name:\n",
    "            params.requires_grad = True\n",
    "        else:\n",
    "            params.requires_grad = False\n",
    "    print(\"Phase 3 - Training last 4 blocks and classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:04:06.636993Z",
     "iopub.status.busy": "2025-03-19T06:04:06.636684Z",
     "iopub.status.idle": "2025-03-19T06:04:06.640943Z",
     "shell.execute_reply": "2025-03-19T06:04:06.640046Z",
     "shell.execute_reply.started": "2025-03-19T06:04:06.636964Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def unfreeze_whole_model(model):\n",
    "    for params in model.parameters():\n",
    "        params.requires_grad = True \n",
    "    print(\"phase 4 - whole model training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:19:54.314030Z",
     "iopub.status.busy": "2025-03-19T06:19:54.313698Z",
     "iopub.status.idle": "2025-03-19T06:19:54.318301Z",
     "shell.execute_reply": "2025-03-19T06:19:54.317200Z",
     "shell.execute_reply.started": "2025-03-19T06:19:54.314003Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "#optimiser = optim.Adam(densenetmodel.parameters(),lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:21:46.274263Z",
     "iopub.status.busy": "2025-03-19T06:21:46.273940Z",
     "iopub.status.idle": "2025-03-19T06:21:54.306283Z",
     "shell.execute_reply": "2025-03-19T06:21:54.304929Z",
     "shell.execute_reply.started": "2025-03-19T06:21:46.274237Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 15\n",
    "phases = [{\"epochs\": 5, \"unfreeze\": freeze_everything_except_classifier, \"lr\": 0.001},{\"epochs\": 5, \"unfreeze\": unfreeze_lasttwo_block, \"lr\": 0.0001},{\"epochs\": 5, \"unfreeze\": unfreeze_last_four_blocks, \"lr\": 0.00001},{\"epochs\": 5, \"unfreeze\": unfreeze_whole_model, \"lr\": 1e-6}]\n",
    "\n",
    "for phase_idx, phase in enumerate(phases):\n",
    "    phase[\"unfreeze\"](efficientnetmodel)\n",
    "    optimiser = optim.Adam(efficientnetmodel.parameters(), lr=phase[\"lr\"])\n",
    "    print(f\"\\n--- starting phase {phase_idx+1}: {phase['unfreeze'].__name__} | Learning Rate: {phase['lr']}\")\n",
    "\n",
    "    for epoch in range(phase[\"epochs\"]):\n",
    "        efficientnetmodel.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.float().to(device)\n",
    "            optimiser.zero_grad()\n",
    "            outputs = efficientnetmodel(inputs).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "\n",
    "        train_accuracy = 100 * correct_train / total_train\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "\n",
    "        print(f\"phase {phase_idx+1} | epoch [{epoch+1}/{phase['epochs']}]: \"\n",
    "              f\"loss = {avg_loss:.4f}, train acc = {train_accuracy:.2f}%\")\n",
    "\n",
    "        checkpoint_filename = f\"efficientnet_phase{phase_idx}_epoch{epoch+1}.pth\"\n",
    "        torch.save(efficientnetmodel.state_dict(), checkpoint_filename)\n",
    "        print(f\"model saved as {checkpoint_filename}\")\n",
    "\n",
    "    efficientnetmodel.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.float().to(device)\n",
    "            outputs = efficientnetmodel(inputs).squeeze()\n",
    "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_accuracy = 100 * correct / total\n",
    "    print(f\"phase {phase_idx+1} val acc: {val_accuracy:.2f}%\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1909705,
     "sourceId": 3134515,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
